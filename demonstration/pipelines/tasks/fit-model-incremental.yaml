apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: fit-model-incremental
  labels:
    app.kubernetes.io/version: "0.6"
  annotations:
    tekton.dev/pipelines.minVersion: "0.17.0"
    tekton.dev/categories: Image Build
    tekton.dev/tags: image-build
    tekton.dev/displayName: "Get historical feature values from offline store"
    tekton.dev/platforms: "linux/amd64"
spec:
  description: >-
    This Task loads the most recent model on MLFlow.
    This Task fits the model on recent data.
  params:
    - name: mlflow_model_name
      description: Name of MLFlow model to load.
    - name: mlflow_tracking_uri
      description: Reachable MLFlow Endpoint.
    - name: mlflow_experiment_name
      description: Name of MLFlow experiment.
    - name: random_state
      description: The random seed.
  workspaces:
    - name: shared-workspace
      description: This workspace contains model parameters from MLFlow.
  results:
    - name: storage-uri
      description: The uri of the stored model in s3.
  steps:
    - name: load-and-fit
      image: docker.io/piepra/ml-executor:1.5
      script: | 
        #!/usr/bin/env bash
        pip install protobuf==3.20.* boto3
        echo "test"
        pyscript=$(cat <<'EOF'   
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        import numpy as np
        import tensorflow as tf
        import pandas as pd
        import mlflow
        from mlflow.models.signature import infer_signature
        import pickle
        import os
        import argparse

        parser = argparse.ArgumentParser(description='Load and Fit Model.')
        parser.add_argument('--mlflow_experiment_name', help='The name of the MLFlow experiment.', type=str, required = True)
        parser.add_argument('--mlflow_tracking_uri', help='Reachable MLFlow URI.', type=str, required = True)
        parser.add_argument('--mlflow_model_name', help='Name of the MLFlow model.', type=str, required = True)
        parser.add_argument('--random_state', help='The random seed.', type=str, default = "42")
        parser.add_argument('--destination', help='The pickle file destination', type=str, default = ".")
        args = parser.parse_args()

        np.random.seed(int(args.random_state))
        tf.random.set_seed(int(args.random_state))

        os.environ["AWS_ACCESS_KEY_ID"] = "mlflow"
        os.environ["AWS_SECRET_ACCESS_KEY"] = "mlflow123"
        os.environ["MLFLOW_S3_ENDPOINT_URL"] = f"http://mlflow-minio.mlflow.svc.cluster.local:9000/"

        mlflow.set_tracking_uri(args.mlflow_tracking_uri)
        mlflow.set_experiment(args.mlflow_experiment_name)

        with open(args.destination + '/run', 'rb') as f:
            run = pickle.load(f)
        with open(args.destination + '/model', 'rb') as f:
            model = pickle.load(f)
        version = model.latest_versions[-1]

        model = mlflow.keras.load_model(
            model_uri=f"models:/{version.name}/{version.version}"
        )
        
        df = pd.read_csv(args.destination + "/features.csv", index_col="event_timestamp")
        df.index = pd.to_datetime(df.index)
        first = df.index[0].timestamp()
        last = df.index[-1].timestamp()
        keys = list(df.columns)
        keys.remove("y")
        X = df[keys]
        y = df["y"]

        with mlflow.start_run():
            mlflow.tensorflow.autolog()
            model.fit(X, y, epochs=5, batch_size=1)
            mlflow.log_param("data_from", first)
            mlflow.log_param("data_to", last)
            mlflow.log_param("feature_view", "crypto_stats")
            mlflow.log_param("framework", "keras")
            lr = {"lr_" + str(key): val for key, val in model.optimizer.get_config().items()}
            mlflow.log_params(lr)
            model_signature = infer_signature(X, y)
            info = mlflow.keras.log_model(model, "model", registered_model_name="BitcoinForecast", signature=model_signature)
            uri = mlflow.get_artifact_uri()
            storage_uri = f"{uri}/model"
        with open("$(results.storage-uri.path)", 'a') as f: f.write(storage_uri)
        EOF
        )
        python -c "$pyscript" --mlflow_tracking_uri $(params.mlflow_tracking_uri) --mlflow_model_name $(params.mlflow_model_name) \
        --mlflow_experiment_name $(params.mlflow_experiment_name) --random_state $(params.random_state) --destination $(workspaces.shared-workspace.path)

  